# Segmentation Stack Comparison

## ðŸŽ¯ Quick Reference

| Approach | Training Required? | Input Type | Best For |
|----------|-------------------|------------|----------|
| **Zero-Shot COCO** | âŒ NO | RGB (3ch) | Common objects (80 COCO classes) |
| **Fine-Tuned Mask2Former** | âœ… YES | RGB (3ch) | Custom object categories |
| **Custom ViT Segmentation** | âœ… YES | RGB/Multispectral (3-5+ ch) | Geological/remote sensing |

---

## ðŸ“Š Detailed Comparison

### 1. Zero-Shot Detection (NEW!)

**Script:** `zero_shot_detection.py`

**No Training Required!** âœ¨

```bash
python zero_shot_detection.py image.jpg --visualize
```

| Pros | Cons |
|------|------|
| âœ… No training needed | âŒ Limited to 80 COCO classes |
| âœ… Instant results | âŒ RGB images only |
| âœ… High accuracy on common objects | âŒ Not customizable |
| âœ… Pre-trained on 118K images | âŒ May not work on specialized domains |

**Use Cases:**
- Detecting people, cars, animals in photos
- Quick prototyping
- Bootstrapping label datasets
- General object detection

**Categories:**
```
person, car, dog, cat, chair, laptop, phone, bicycle, truck, bird,
horse, sheep, cow, bottle, cup, knife, spoon, bowl, banana, apple,
sandwich, orange, pizza, cake, couch, tv, book, clock, vase, etc.
```

---

### 2. Fine-Tuned Mask2Former

**Script:** `train_mask2former_deepgis.py`

**Training Required:** Yes (custom categories)

```bash
# Convert labels to COCO format
python train_mask2former_deepgis.py --mode convert --image_dir /path/to/images

# Train on custom categories
python train_mask2former_deepgis.py --mode train --image_dir /path/to/images --num_epochs 50
```

| Pros | Cons |
|------|------|
| âœ… Custom object categories | âŒ Requires labeled training data |
| âœ… State-of-the-art accuracy | âŒ Training time (hours) |
| âœ… Transfer learning from COCO | âŒ RGB only (3 channels) |
| âœ… Panoptic segmentation | âŒ Requires detectron2 |

**Use Cases:**
- Custom object detection (rocks, minerals, equipment)
- High-accuracy instance segmentation
- When COCO classes aren't enough

**Example Custom Categories:**
```python
categories = ['granite', 'basalt', 'sandstone', 'limestone', 'shale']
```

**Architecture:**
```
Pre-trained COCO â†’ Fine-tune on custom data â†’ Custom predictions
```

---

### 3. Multispectral ViT Segmentation

**Scripts:** `multispectral_vit.py` + `multispectral_decoder.py` + `segmentation_assisted_labeling.py`

**Training Required:** Yes (from scratch, no pre-training)

```bash
# Train autoencoder first
python train_autoencoder.py --img_size 960 --in_channels 5

# Then train segmentation decoder
# (requires custom training script)
```

| Pros | Cons |
|------|------|
| âœ… Multispectral support (5+ bands) | âŒ No pre-trained weights |
| âœ… Cross-band attention (unique!) | âŒ Train from scratch (slow) |
| âœ… Designed for remote sensing | âŒ Requires large dataset |
| âœ… Handles NIR, RedEdge bands | âŒ Complex architecture |

**Use Cases:**
- Multispectral/hyperspectral imagery
- Geological feature mapping
- Vegetation analysis (NDVI, NDRE)
- Drone/satellite imagery
- When spectral information is critical

**Input Bands:**
```
Band 1: Blue (475nm)
Band 2: Green (560nm)
Band 3: Red (668nm)
Band 4: Red Edge (717nm)
Band 5: Near-Infrared (840nm)
```

**Unique Feature: Cross-Band Attention**
```python
# Learns relationships between spectral bands
# E.g., NIR/Red ratio for vegetation
x = x + self.cross_band_attn(x)
```

---

### 4. Baseline Mask R-CNN

**Script:** `deepgis-xr/deepgis_xr/apps/ml/services/predictor.py`

**Training Required:** Optional (can use pre-trained)

| Pros | Cons |
|------|------|
| âœ… Simple, well-documented | âŒ Less accurate than Mask2Former |
| âœ… Fast inference | âŒ Not state-of-the-art |
| âœ… TorchVision (easy install) | âŒ Instance segmentation only |
| âœ… Pre-trained COCO weights | âŒ No panoptic segmentation |

**Use Cases:**
- Quick baseline model
- Real-time applications
- When speed > accuracy

---

## ðŸ”€ Decision Tree

```
Do you need to detect objects in an image?
â”‚
â”œâ”€ Are they common objects? (people, cars, animals, furniture)
â”‚  â”‚
â”‚  â”œâ”€ YES â†’ âœ… Use Zero-Shot Detection (no training!)
â”‚  â”‚         Script: zero_shot_detection.py
â”‚  â”‚
â”‚  â””â”€ NO â†’ Continue below...
â”‚
â”œâ”€ Is the image RGB (3 channels)?
â”‚  â”‚
â”‚  â”œâ”€ YES â†’ Do you need custom categories?
â”‚  â”‚        â”‚
â”‚  â”‚        â”œâ”€ YES â†’ âœ… Fine-Tune Mask2Former
â”‚  â”‚        â”‚         Script: train_mask2former_deepgis.py
â”‚  â”‚        â”‚
â”‚  â”‚        â””â”€ NO â†’ âœ… Use Zero-Shot Detection
â”‚  â”‚
â”‚  â””â”€ NO (Multispectral/5+ bands) â†’ âœ… Custom ViT Segmentation
â”‚                                     Scripts: multispectral_vit.py
â”‚
â””â”€ Do you have labeled training data?
   â”‚
   â”œâ”€ NO â†’ 
   â”‚      â”œâ”€ Start with Zero-Shot to bootstrap labels
   â”‚      â””â”€ Then refine and train custom model
   â”‚
   â””â”€ YES â†’
          â”œâ”€ < 100 images â†’ Use Zero-Shot or augment data
          â”œâ”€ 100-1000 images â†’ Fine-Tune Mask2Former
          â””â”€ 1000+ images â†’ Custom ViT (if multispectral)
```

---

## ðŸ’» Example Workflows

### Workflow 1: Quick Object Detection (No Training)

```bash
# Detect objects in any image
python zero_shot_detection.py street_scene.jpg --visualize

# Result: Detects people, cars, bicycles, etc.
# Time: ~1-5 seconds per image
# Training time: 0 hours âœ¨
```

**Output:**
```json
{
  "detections": [
    {"class_name": "person", "confidence": 0.98},
    {"class_name": "car", "confidence": 0.95},
    {"class_name": "bicycle", "confidence": 0.87}
  ]
}
```

---

### Workflow 2: Custom Object Categories (RGB)

```bash
# 1. Label your data in DeepGIS
# Categories: ['rock_type_A', 'rock_type_B', 'rock_type_C']

# 2. Convert to COCO format
python train_mask2former_deepgis.py --mode convert --image_dir images/

# 3. Train Mask2Former
python train_mask2former_deepgis.py --mode train \
    --image_dir images/ \
    --num_epochs 50 \
    --batch_size 4

# 4. Predict on new images
python train_mask2former_deepgis.py --mode predict \
    --model_path checkpoints/model_final.pth \
    --image_path test_image.jpg

# Training time: 2-6 hours (depends on dataset size)
```

---

### Workflow 3: Multispectral Segmentation

```bash
# 1. Train encoder (unsupervised)
python train_autoencoder.py \
    --img_size 960 \
    --in_channels 5 \
    --num_epochs 100

# 2. Train segmentation decoder (supervised)
# (Requires custom script with labeled multispectral data)

# 3. Run inference
python segmentation_assisted_labeling.py \
    --model_path multispectral_segmentation_model.pth \
    --config_path multispectral_vit.pth

# Training time: 10-20 hours (from scratch)
```

---

## ðŸ“ˆ Performance Comparison

### Accuracy (on respective domains)

| Model | Common Objects | Custom Objects | Multispectral |
|-------|----------------|----------------|---------------|
| Zero-Shot COCO | â­â­â­â­â­ | â­ | â­ |
| Fine-Tuned Mask2Former | â­â­â­ | â­â­â­â­â­ | â­ |
| Custom ViT | â­ | â­â­â­ | â­â­â­â­â­ |

### Speed (inference)

| Model | GPU (FPS) | CPU (FPS) | Memory |
|-------|-----------|-----------|--------|
| Zero-Shot Mask R-CNN | 10-15 | 2-3 | 2-4 GB |
| Mask2Former | 5-8 | 1-2 | 4-8 GB |
| Custom ViT | 8-12 | 1-2 | 3-6 GB |

### Training Time

| Model | Dataset Size | Training Time | Labels Required |
|-------|--------------|---------------|-----------------|
| Zero-Shot | N/A | **0 hours** âœ¨ | 0 |
| Mask2Former | 500 images | 2-4 hours | 500+ |
| Custom ViT | 5000 tiles | 10-20 hours | 5000+ |

---

## ðŸŽ“ Summary Table

| Model | Input | Training | Classes | Accuracy | Speed | Best For |
|-------|-------|----------|---------|----------|-------|----------|
| **Zero-Shot** | RGB | âŒ None | 80 COCO | â­â­â­â­ | âš¡âš¡âš¡ | Common objects, prototyping |
| **Mask2Former** | RGB | âœ… Fine-tune | Custom | â­â­â­â­â­ | âš¡âš¡ | Custom categories, high accuracy |
| **ViT Segmentation** | Multi | âœ… From scratch | Custom | â­â­â­â­ | âš¡âš¡ | Multispectral, remote sensing |
| **Mask R-CNN** | RGB | âš™ï¸ Optional | 80/Custom | â­â­â­ | âš¡âš¡âš¡ | Baseline, real-time |

---

## ðŸš€ Getting Started

### New to Segmentation?
```bash
# Start here - no training required!
python zero_shot_detection.py your_image.jpg --visualize
```

### Have Labeled RGB Data?
```bash
# Fine-tune on your categories
python train_mask2former_deepgis.py --mode train --image_dir images/
```

### Working with Multispectral?
```bash
# Train custom ViT
python train_autoencoder.py --in_channels 5
```

---

## ðŸ“š Documentation

- **Zero-Shot:** [ZERO_SHOT_DETECTION.md](ZERO_SHOT_DETECTION.md)
- **Mask2Former:** `train_mask2former_deepgis.py` (docstring)
- **ViT Segmentation:** [ENCODER_DECODER_GUIDE.md](ENCODER_DECODER_GUIDE.md)
- **Architecture:** [UNIQUE_FEATURES.md](UNIQUE_FEATURES.md)

---

## â“ FAQ

### Q: Can I detect custom objects without training?
**A:** No. Zero-shot only works for the 80 COCO categories. For custom objects, you need to fine-tune or train from scratch.

### Q: Which model should I use?
**A:** 
- Common objects â†’ Zero-Shot
- Custom RGB categories â†’ Mask2Former
- Multispectral â†’ Custom ViT

### Q: How much training data do I need?
**A:**
- Zero-Shot: 0 images âœ¨
- Fine-tuning: 100-1000 images (more is better)
- From scratch: 1000+ images

### Q: Can I use multispectral with Mask2Former?
**A:** Not directly. Mask2Former expects RGB (3 channels). For multispectral, use the custom ViT segmentation model.

---

**ðŸŽ¯ Bottom Line:**

- **Detection without training?** â†’ âœ… YES (80 COCO classes only)
- **Custom objects?** â†’ âš ï¸ NO (training required)
- **Multispectral?** â†’ âš ï¸ NO (custom model required)

---

**Created:** 2025-11-07  
**Last Updated:** 2025-11-07

